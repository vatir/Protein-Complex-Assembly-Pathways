{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, deque\n",
    "import numpy as np\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import write_dot\n",
    "from networkx.drawing.nx_pydot import pydot_layout\n",
    "import matplotlib as mpl\n",
    "# mpl.use('pdf')\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox, TextArea, DrawingArea\n",
    "from matplotlib.patches import Circle\n",
    "from numba import jit\n",
    "# import pickle\n",
    "import cPickle as pickle\n",
    "import gzip\n",
    "\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.utf8')\n",
    "\n",
    "import os\n",
    "import psutil\n",
    "process = psutil.Process(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 1600\n",
    "mpl.rcParams['figure.figsize'] = (\n",
    "    20,\n",
    "    20\n",
    "    )\n",
    "mpl.rcParams['savefig.transparent'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52  1 1 0.1 0 0.png\n",
      "51  1 1 0.0 1 1.png\n",
      "56  1 1 1.0 0 0.png\n",
      "53  1 1 0.1 0 1.png\n",
      "54  1 1 0.1 1 0.png\n",
      "50  1 1 0.0 1 0.png\n",
      "32  1 0 0.0 0 0.png\n",
      "48  1 1 0.0 0 0.png\n",
      "36  1 0 0.1 0 0.png\n",
      "63  1 1 1.1 1 1.png\n",
      "60  1 1 1.1 0 0.png\n",
      "62  1 1 1.1 1 0.png\n"
     ]
    }
   ],
   "source": [
    "# Import Images\n",
    "Images = dict()\n",
    "from glob import glob\n",
    "for item in glob(\"./AllPatterns/*.png\"):\n",
    "    try:\n",
    "        Filename = item.split(\"/\")[2]\n",
    "        print Filename\n",
    "        Images[int(Filename[:2])] = Filename\n",
    "    except:\n",
    "        print Filename\n",
    "        raise SystemExit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "def PrintIter(ob):\n",
    "    frame = inspect.currentframe()\n",
    "    frame = inspect.getouterframes(frame)[1]\n",
    "    string = inspect.getframeinfo(frame[0]).code_context[0].strip()\n",
    "    arg = string[string.find('(') + 1:-1].split(',')[0]\n",
    "#     print arg\n",
    "#     print \"{} : {}\".format([ k for k,v in locals().iteritems() if (v == ob and not k == 'ob')][0], type(ob))\n",
    "    print \"{} : {}\\n\".format(arg, type(ob))\n",
    "    if type(ob) == OrderedDict or type(ob) == dict:\n",
    "        for x, y in ob.items():\n",
    "            print \"{: >2} : {}\".format(x, y)\n",
    "    elif (type(ob) == list or type(ob) == np.ndarray) and not arg==\"D.Reactions\":\n",
    "        for x, y in enumerate(ob):\n",
    "            print \"{: >2} : {}\".format(x, y)\n",
    "    elif arg==\"D.Reactions\":\n",
    "#         print \"Converted to Species Int:\"\n",
    "        for x, y in enumerate(ob):\n",
    "            print \"{: >3} : {: >2}, {: >2} -> {: >2} : {}\".format(x, D.ReactionRelations(y)[0],D.ReactionRelations(y)[1],D.ReactionRelations(y)[2], y)\n",
    "    else:\n",
    "        print ob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpeciesToRepString(Species, N=3):\n",
    "    if isinstance(Species, np.ndarray):\n",
    "        Out = map(str, Species.flatten())\n",
    "        Out = \",\".join(Out[:N]) + \";\" + \",\".join(Out[N:])\n",
    "        return Out\n",
    "    if isinstance(Species, int):\n",
    "        Out = [x for x in str(bin(Species)[2:].zfill(N*2))]\n",
    "        Out = \",\".join(Out[:N]) + \";\" + \",\".join(Out[N:])\n",
    "        return Out\n",
    "    if isinstance(Species, str) and len(Species) > 4*N-1:\n",
    "        return Species[:N*4-1]\n",
    "    elif len(Species) == N*4-1:\n",
    "        return Species\n",
    "#     Cur = Species.split(\" \")\n",
    "#     if len(Cur) == 2 and len(Cur[0]) == 4*N-1:\n",
    "#         return Cur[0]\n",
    "#     if Cur[0] == Species:\n",
    "#         return Species\n",
    "    return False\n",
    "\n",
    "def SpeciesToArrays(Species, N=3):\n",
    "    Cur = SpeciesToRepString(Species, N)\n",
    "    Cur = np.array([x.split(\",\") for x in Cur.split(\";\")], dtype=\"b\")\n",
    "    return Cur\n",
    "\n",
    "def SpeciesArrayToInt(Species):\n",
    "    Species = SpeciesToArrays(Species)\n",
    "    return int(np.sum([x*(2**n) for n,x in enumerate(Species.flatten()[::-1])]))\n",
    "\n",
    "def Symmetries(Species, N=3, Unique = True, Ints=False, Sorted=True):\n",
    "    '''\n",
    "    Symmetries(Species, N=3, Unique = True, Ints=False, Sorted=True)\n",
    "    Sorted = False results in the index consistantly representing the same symmetry\n",
    "    Results are sorted, so first entry is always the \"Cannonical Rep\"\n",
    "    '''\n",
    "    Cur = SpeciesToArrays(SpeciesToRepString(Species, N), N)\n",
    "    Syms = []\n",
    "    Syms.append(Cur) # Identity\n",
    "    for I in range(1,N): # Rotational Symmetries (C_N)\n",
    "        Syms.append(np.roll(Cur, I, axis=1))\n",
    "    for I in range(len(Syms)): # Reflection Symmetries\n",
    "        Syms.append(Syms[I][::-1])\n",
    "#     for S in Syms:\n",
    "#         print(\"{} : {} : {}\".format(SpeciesArrayToInt(S),SpeciesToRepString(S),S))\n",
    "    if Unique:\n",
    "#         print set(map(SpeciesArrayToInt,Syms))\n",
    "        Out = map(SpeciesToArrays,set(map(SpeciesArrayToInt,Syms)))\n",
    "    else:\n",
    "        Out = Syms\n",
    "    if Sorted:\n",
    "        Out = sorted(Out, key=SpeciesArrayToInt)\n",
    "    else:\n",
    "        pass\n",
    "    Out = [SpeciesToRepString(x, N) for x in Out]\n",
    "    if Ints:\n",
    "        return map(SpeciesArrayToInt,Out[::-1])\n",
    "    else:\n",
    "        return [SpeciesToRepString(x, N) for x in Out[::-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def SpeciesToIndex(S, Species):\n",
    "#     return int(np.where(np.array(Species.values())==S)[0])\n",
    "def SpeciesToIndex(S, Species = False):\n",
    "    SpeciesIndex = {y:i for (i, (x,y)) in enumerate(Species.items())}\n",
    "    return SpeciesIndex[S]\n",
    "\n",
    "# def SpeciesToInt(S):\n",
    "#     return int(S[::2],2)\n",
    "def SpeciesToName(S, Species):\n",
    "    return Species.values()[S]\n",
    "\n",
    "class Probabilities(object):\n",
    "    def __init__(self, Data, Concentrations=False):\n",
    "        self.Data = Data\n",
    "        self.ProteinsInSpecies = [sum(x == \"1\" for x in Data.Species.values()[i]) for i in range(Data.SpeciesCount)]\n",
    "        self._GenReactionsByProduct()\n",
    "        self.UpdateNorms(Concentrations)\n",
    "\n",
    "    def LookupReaction(self, Product, R1 = -1, R2 = -1):\n",
    "        Out = deque()\n",
    "        for R in self.Data.Reactions:\n",
    "            if R[3] == Product:\n",
    "                Out.append(R)\n",
    "        if R1 == -1 and R2 == -1:\n",
    "            return Out\n",
    "        R1 = int(R1)\n",
    "        R2 = int(R2)\n",
    "        for R in Out:\n",
    "            if R[0] == R1 and R[1] == R2:\n",
    "                return R\n",
    "            if R[1] == R1 and R[0] == R2:\n",
    "                return R\n",
    "        return False\n",
    "\n",
    "    def _GenReactionsByProduct(self):\n",
    "        ReactionsByProduct = OrderedDict()\n",
    "        for Species in self.Data.SpeciesConvert.values():\n",
    "            for R in self.LookupReaction(Species):\n",
    "                try:\n",
    "                    ReactionsByProduct[Species].append(R)\n",
    "                except:\n",
    "                    ReactionsByProduct[Species] = list()\n",
    "                    ReactionsByProduct[Species].append(R)\n",
    "        self.ReactionsByProduct = ReactionsByProduct\n",
    "\n",
    "    def UpdateNorms(self, Concentrations = False): \n",
    "        # Generate the normalization factors (Return list in the same order as the Data.Species list)\n",
    "        if hasattr(Concentrations, '__iter__'):\n",
    "            NormsBySpecies = np.zeros(len(Concentrations))\n",
    "        else:\n",
    "            Concentrations = np.ones(self.Data.SpeciesCount)\n",
    "            NormsBySpecies = np.zeros(self.Data.SpeciesCount)\n",
    "\n",
    "        for i, Rs in self.ReactionsByProduct.items():\n",
    "            #print \"{} : {}\".format(i,Rs)\n",
    "            for R in Rs:\n",
    "                # R[2]: Forward\n",
    "                # R[0]: Reactant 1\n",
    "                # R[1]: Reactant 2\n",
    "                # R[3]: Product\n",
    "                NormsBySpecies[i] += R[2]*Concentrations[R[0]]*Concentrations[R[1]]\n",
    "                #print \"{} : {}\".format(R, NormsBySpecies[i])\n",
    "        self.Concentrations = Concentrations \n",
    "        self.NormsBySpecies = NormsBySpecies\n",
    "\n",
    "    def UpdateConcentrations(self, Fraction, Concentration): \n",
    "        #RealConc = np.zeros_like(Fraction)\n",
    "        RealConc = Fraction*Concentration/self.ProteinsInSpecies\n",
    "        self.UpdateNorms(RealConc)\n",
    "\n",
    "    def ReactionFlux(self, Product, R1, R2):\n",
    "        Forward = self.LookupReaction(Product, R1, R2)\n",
    "        if hasattr(Forward, '__iter__'):\n",
    "            Forward = Forward[2]\n",
    "        else:\n",
    "            print \"Reaction for P: {} R1: {} R2: {} Not Found!!!!\".format(Product, R1, R2)\n",
    "        if self.Concentrations[R1]*self.Concentrations[R2] != 0.0:\n",
    "            return Forward*self.Concentrations[R1]*self.Concentrations[R2]/(self.NormsBySpecies[Product])\n",
    "        return 0.0\n",
    "\n",
    "    def NodeFlux(self, Graph, Node = \"Root\"):\n",
    "        if Node == \"Root\":\n",
    "            Node = self.Data.Species.values()[-1] # Root Node Name\n",
    "        Product = nx.get_node_attributes(Graph,\"Product\")[Node]\n",
    "        R1 = nx.get_node_attributes(Graph,\"Reactant1\")[Node]\n",
    "        R2 = nx.get_node_attributes(Graph,\"Reactant2\")[Node]\n",
    "        return self.ReactionFlux(Product,R1,R2)\n",
    "\n",
    "    def PathIndependentFlux(self, Graph, Probability = True):\n",
    "        Product = nx.get_node_attributes(Graph,\"Product\").values()\n",
    "        R1 = nx.get_node_attributes(Graph,\"Reactant1\").values()\n",
    "        R2 = nx.get_node_attributes(Graph,\"Reactant2\").values()\n",
    "        Flux = 1.0\n",
    "        for i in range(len(Product)):\n",
    "            Flux *= self.ReactionFlux(Product[i],R1[i],R2[i])\n",
    "        if not Probability:\n",
    "            # Remove normalization from last step\n",
    "            Flux *= self.NormsBySpecies[-1]\n",
    "        return Flux\n",
    "\n",
    "    def GetChildren(self, Graph, Node):\n",
    "        return Graph.successors(Node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class Pathway(object):\n",
    "    def __init__(self):\n",
    "        self.childrendict = dict()\n",
    "        self.degreedict = dict()\n",
    "    \n",
    "    def degree(self):\n",
    "        return self.degreedict\n",
    "    \n",
    "    def nodes(self, data=False):\n",
    "        return tuple(self.degreedict.keys())\n",
    "\n",
    "    def add_node(self, nodename):\n",
    "        if len(self.nodes()) == 0:\n",
    "            self.degreedict[nodename] = 1\n",
    "        else:\n",
    "            self.degreedict[nodename] = 0\n",
    "    \n",
    "    def children(self, nodename):\n",
    "        try:\n",
    "            return self.childrendict[nodename]\n",
    "        except:\n",
    "            return ()\n",
    "    \n",
    "    def add_edge(self, node1, node2):\n",
    "        try:\n",
    "            self.degreedict[node2] += 1\n",
    "        except:\n",
    "            self.degreedict[node2] = 1\n",
    "        try:\n",
    "            self.childrendict[node1].append(node2)\n",
    "            self.degreedict[node1] += 1\n",
    "        except:\n",
    "            self.degreedict[node1] = 2\n",
    "            self.childrendict[node1]=list([node2])\n",
    "            \n",
    "    def edges(self):\n",
    "        Edge = []\n",
    "        for key, value in self.childrendict.items():\n",
    "            for v in value:\n",
    "                Edge.append((key, v))\n",
    "        return tuple(Edge)\n",
    "        \n",
    "    def copy(self):\n",
    "        New = Pathway()\n",
    "        New.childrendict = copy.copy(self.childrendict)\n",
    "        New.degreedict = copy.copy(self.degreedict)\n",
    "        return New\n",
    "\n",
    "#     def copy(self):\n",
    "#         New = Pathway()\n",
    "#         New.childrendict = copy.deepcopy(self.childrendict)\n",
    "#         New.degreedict = copy.deepcopy(self.degreedict)\n",
    "#         return New\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImportedData(object):\n",
    "    def __init__(self, N = 3):\n",
    "        self.N = N\n",
    "        self.SymCount = 2*N\n",
    "        self.GetSDataFromFiles(\"species{}\".format(N))\n",
    "        self.GetRDataFromFiles(\"react{}\".format(N))\n",
    "        #         Sort Species\n",
    "        self.MonomerCount = int(len(self.Species.values()[0])/2)\n",
    "        self.RootNodeName = SpeciesToRepString(2**(2*N)-1, N)\n",
    "        self.MonomerName  = SpeciesToRepString(2**(2*N-1), N)\n",
    "        self.SpeciesIndex = {y:i for (i, (x,y)) in enumerate(self.Species.items())}\n",
    "        self.CreateReactionLookup()\n",
    "        self.SpeciesRepList = self.Species.values()\n",
    "        \n",
    "    def CreateReactionLookup(self):\n",
    "        Reactions = np.array(self.Reactions)\n",
    "        self.ReactionLookupBySpecies = dict()\n",
    "        for i, Key in enumerate(map(frozenset, Reactions[:,(0,1,3)])):\n",
    "            self.ReactionLookupBySpecies[Key] = i\n",
    "    \n",
    "    def GetSDataFromFiles(self, filename):\n",
    "        try:\n",
    "            self.Species = OrderedDict()\n",
    "            with open(filename,\"r\") as SpeciesFile:\n",
    "                SpeciesList = SpeciesFile.read().strip().split(\"\\n\")\n",
    "                for S in SpeciesList:\n",
    "                    L = S.split(\";;\")\n",
    "                    self.Species[int(L[0])] = L[1]\n",
    "        \n",
    "            self.Species = OrderedDict(sorted(self.Species.items(), key=lambda x: x[0]))\n",
    "            self.SpeciesConvert = OrderedDict()\n",
    "            for i, S in enumerate(map(int,self.Species.keys())):\n",
    "                self.SpeciesConvert[int(S)] = i\n",
    "\n",
    "            self.SpeciesCount = len(self.Species.keys())\n",
    "            self.SpeciesNumbers = np.unique(np.array([Symmetries(x, Ints=True, Unique=False) for x in self.Species.keys()[::-1]]).flatten())\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def GetRDataFromFiles(self, filename):\n",
    "        try:\n",
    "            self.Reactions = []\n",
    "            with open(filename,\"r\") as ReactFile:\n",
    "                ReactList = ReactFile.read().strip().split(\"\\n\")\n",
    "                ReactList = map(lambda x: x.split(\"\\t\"), ReactList)\n",
    "                for R in ReactList:\n",
    "                    R = map(lambda x: x.split(\";;\"), R)\n",
    "                    R = map(lambda x: x[0], R)\n",
    "                    R = map(lambda x: x.split(\",\"), R)\n",
    "                    # Drop Representation\n",
    "                    R = list(itertools.chain(*R))\n",
    "                    R = map(int, R)\n",
    "                    R[0]=self.SpeciesConvert[R[0]]\n",
    "                    R[1]=self.SpeciesConvert[R[1]]\n",
    "                    if R[0] > R[1]:\n",
    "                        R0 = R[0]\n",
    "                        R1 = R[1]\n",
    "                        R[0] = R1\n",
    "                        R[1] = R0\n",
    "                    R[3]=self.SpeciesConvert[R[3]]\n",
    "                    self.Reactions.append(R)\n",
    "\n",
    "                # Sort Reactions by Product, R1, R2 (R1 is always less than R2)\n",
    "                SortList = map(list,list(np.array(self.Reactions)[:,(3,0,1)]))\n",
    "                L = range(len(SortList))\n",
    "                for i in L:\n",
    "                    SortList[i].append(i)\n",
    "                SortOrder = np.array(sorted(SortList))[:,3]\n",
    "                self.Reactions = map(list,list(np.array(self.Reactions)[SortOrder]))\n",
    "                \n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print e\n",
    "            return False\n",
    "        \n",
    "    def ReactionValue(self, Node, Graph): # Used for cannonical definition\n",
    "        def AddToNode(N):\n",
    "            if N >= 0:                \n",
    "                ##  0  1 2 3  4  5 6\n",
    "                ## R1 R2 F P B1 B2 R\n",
    "                Graph.add_node(Node, {\n",
    "                                            \"RIndex\":N,\n",
    "                                            \"Forward\":self.Reactions[N][2],\n",
    "                                            \"Reverse\":self.Reactions[N][6],\n",
    "                                            \"BondType1\":self.Reactions[N][4],\n",
    "                                            \"BondType2\":self.Reactions[N][5],\n",
    "                                            \"Product\":self.Reactions[N][3],\n",
    "                                            \"Reactant1\":self.Reactions[N][0],\n",
    "                                            \"Reactant2\":self.Reactions[N][1],\n",
    "                                            })\n",
    "            else:\n",
    "                Graph.add_node(Node, RIndex = -1)\n",
    "#         P = SpeciesToIndex(Node.split(\" \")[0], self.Species)\n",
    "        P = self.SpeciesIndex[Node[:self.N*4-1]]\n",
    "#         if P == min(self.SpeciesConvert.values()):\n",
    "        if P == 0:\n",
    "            AddToNode(-1)\n",
    "            return 0\n",
    "        #if P == min(self.SpeciesConvert.values()) or P == max(self.SpeciesConvert.values()):\n",
    "        #    AddToNode(0)\n",
    "        #    return 0\n",
    "        R1, R2 = Graph.succ[Node].keys()\n",
    "\n",
    "        R1 = self.SpeciesIndex[R1[:self.N*4-1]]\n",
    "        R2 = self.SpeciesIndex[R2[:self.N*4-1]]\n",
    "#         R1 = SpeciesToIndex(R1.split(\" \")[0], self.Species)\n",
    "#         R2 = SpeciesToIndex(R2.split(\" \")[0], self.Species)\n",
    "        i = self.ReactionLookupBySpecies[frozenset([P, R1, R2])]\n",
    "        AddToNode(i)\n",
    "        return i+1\n",
    "#         for i, R in enumerate(self.Reactions):\n",
    "#             if P == R[3]:\n",
    "#                 if R1 in R[:2] and R2 in R[:2]:\n",
    "#                     AddToNode(i)\n",
    "#                     return i+1\n",
    "#         else:\n",
    "#             raise KeyError\n",
    "            \n",
    "    def SpeciesNumberLookup(self, SN):\n",
    "        return np.argmax(self.SpeciesNumbers==SN)\n",
    "    \n",
    "    def ReactionRelations(self, Reaction):\n",
    "        '''\n",
    "        def ReactionRelations(self, Reaction)\n",
    "        Returned the Int reps of the Product and Reactants fo the Reaction Array Sumbitted.\n",
    "        '''\n",
    "        return (self.Species.keys()[Reaction[3]], self.Species.keys()[Reaction[0]], self.Species.keys()[Reaction[1]])\n",
    "    \n",
    "    def FindReactions(self, Reaction):\n",
    "        PRep = SpeciesToRepString(Parent, self.N)\n",
    "        \n",
    "    \n",
    "    def KnownStructureCheck(self, Entry):\n",
    "        if np.sum(self.SpeciesNumbers == SpeciesArrayToInt(Entry)) > 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def Children(self, Parent, Child):\n",
    "        '''\n",
    "        Parent : int\n",
    "        Child1 : int\n",
    "        Child2 : int\n",
    "        '''\n",
    "        PAS = np.array(Symmetries(Parent, Unique=False, Ints=True, Sorted=True))\n",
    "        C1S = np.array(Symmetries(Child, Unique=False, Ints=True, Sorted=True))\n",
    "        PI  = np.argmax(PAS == Parent)\n",
    "        PC  = PAS[PI]\n",
    "        I = 0\n",
    "        while True:\n",
    "            C1C = C1S[PI + I]\n",
    "            PA = SpeciesToArrays(PC)\n",
    "            C1 = SpeciesToArrays(C1C)\n",
    "            C2 = PA - C1\n",
    "            if I > 7:\n",
    "                return False\n",
    "            if self.KnownStructureCheck(SpeciesArrayToInt(C2)):\n",
    "                break\n",
    "            I += 1\n",
    "#         print PA\n",
    "#         print C1\n",
    "#         print C2\n",
    "    #     if (PA != C1+C2).all():\n",
    "    #         return False\n",
    "    #     if np.sum(PA) != (np.sum(C1) + np.sum(C1)):\n",
    "    #         return False\n",
    "        POut = SpeciesArrayToInt(PA)\n",
    "        C1Out = SpeciesArrayToInt(C1)\n",
    "        C2Out = SpeciesArrayToInt(C2)\n",
    "        if self.SpeciesNumberLookup(C1Out) > self.SpeciesNumberLookup(C2Out):\n",
    "            pass\n",
    "        else:\n",
    "            CT = C1Out\n",
    "            C1Out = C2Out\n",
    "            C2Out = CT\n",
    "    #     return self.SpeciesNumberLookup(POut), self.SpeciesNumberLookup(C1Out), self.SpeciesNumberLookup(C2Out)\n",
    "        return POut, C1Out, C2Out\n",
    "    #     return SpeciesToArrays(POut), SpeciesToArrays(C1Out), SpeciesToArrays(C2Out)\n",
    "    \n",
    "# def AddReactionDataToGraph(Graph, Data):\n",
    "#     map(lambda i: Data.ReactionValue(i, Graph), Graph.nodes())\n",
    "#     return list()\n",
    "\n",
    "def LeftRight(N1, N2, Graph, Data):\n",
    "    R1 = Graph.node[N1][\"RIndex\"]\n",
    "    R2 = Graph.node[N2][\"RIndex\"]\n",
    "    if R1 > R2:\n",
    "        return N1, N2\n",
    "    elif R1 < R2:\n",
    "        return N2, N1\n",
    "    elif R1 == R2:\n",
    "        R1 = CannonicalGraph(Graph, Data, Start = N1).values()\n",
    "        R2 = CannonicalGraph(Graph, Data, Start = N2).values()\n",
    "        for i in range(max(len(R1), len(R2))):\n",
    "            try:\n",
    "                if R1[i] > R2[i]:\n",
    "                    return N1, N2\n",
    "                if R1[i] < R2[i]:\n",
    "                    return N2, N1\n",
    "            except Exception as e:\n",
    "                print e\n",
    "                if len(R1) > len(R2):\n",
    "                    return N1, N2\n",
    "                elif len(R2) > len(R1):\n",
    "                    return N2, N1\n",
    "            return N1, N2\n",
    "\n",
    "# def CannonicalGraph(Graph, Data, Start):\n",
    "#     map(lambda i: Data.ReactionValue(i, Graph), Graph.nodes())\n",
    "#     return frozenset(Graph.nodes())\n",
    "\n",
    "def CannonicalGraph(Graph, Data, Start):\n",
    "    map(lambda i: Data.ReactionValue(i, Graph), Graph.nodes())\n",
    "#     AddReactionDataToGraph(Graph, Data)\n",
    "    CForm = OrderedDict()\n",
    "    Todo = deque()\n",
    "    Todo.append(Start)\n",
    "    while len(Todo) > 0:\n",
    "        C = Todo.popleft()\n",
    "        CForm[C] = Graph.node[C][\"RIndex\"]\n",
    "        Children = Graph.succ[C].keys()\n",
    "        if len(Children) != 2:\n",
    "            pass\n",
    "        else:\n",
    "            C1, C2 = Children\n",
    "            R1 = Graph.node[C1][\"RIndex\"]\n",
    "            R2 = Graph.node[C2][\"RIndex\"]\n",
    "            I1, I2 = LeftRight(C1, C2, Graph, Data)\n",
    "            Todo.appendleft(I1)\n",
    "            Todo.append(I2)\n",
    "    return CForm\n",
    "\n",
    "Max = 1\n",
    "def UniqueNodeName(Graph, NodeName):\n",
    "    global Max\n",
    "    Max += 1\n",
    "    return \"{} {}\".format(NodeName,Max)\n",
    "\n",
    "import itertools\n",
    "\n",
    "def NodeConvert(NodeName, Data):\n",
    "    IntValue = Data.SpeciesIndex[NodeName[:Data.N*4-1]]\n",
    "    return (IntValue, NodeName)\n",
    "\n",
    "def ChildrenValues(Node, Graph, Data):\n",
    "#     Children = Graph.succ[Node].keys()\n",
    "    Children = Graph.children(Node)\n",
    "    return sorted([(Data.SpeciesIndex[NodeName[:Data.N*4-1]], NodeName) for NodeName in Children if Data.SpeciesIndex[NodeName[:Data.N*4-1]] != 0])\n",
    "\n",
    "def CannonicalIndices(Graph, Data, Start):\n",
    "    # Not Needed for Pathway calculations, but is needed for flux calculations\n",
    "#     map(lambda i: Data.ReactionValue(i, Graph), Graph.nodes())\n",
    "    \n",
    "    CForms = set()\n",
    "    StartNodeInt = NodeConvert(Start, Data)[0]\n",
    "    \n",
    "    BranchingNumber = 0\n",
    "    ChildrenLookup = dict()\n",
    "    BranchingChildren = dict()\n",
    "    for Node in Graph.nodes():\n",
    "        ChildrenLookup[Node] = ChildrenValues(Node, Graph, Data)\n",
    "        if len(ChildrenLookup[Node]) == 2:\n",
    "            BranchingChildren[Node] = ChildrenLookup[Node]\n",
    "            BranchingNumber += 1\n",
    "    BranchingNumber = len(BranchingChildren.keys())\n",
    "    \n",
    "    # Left Right Branching True = Left False = Right\n",
    "    Combinations = [x for x in itertools.combinations_with_replacement((True,False),BranchingNumber)]\n",
    "#     PrintIter(BranchingChildren)\n",
    "#     PrintIter(Combinations)\n",
    "    for C in Combinations:\n",
    "        C = deque(C)\n",
    "        Todo = deque()\n",
    "        Todo.append(Start)\n",
    "        CForm = []\n",
    "        while len(Todo) > 0:\n",
    "            CNode = Todo.pop()\n",
    "            Children = ChildrenLookup[CNode]\n",
    "            if len(Children) == 2:\n",
    "                Branch = C.pop()\n",
    "                if Branch:\n",
    "                    CForm.append(Children[0][0])\n",
    "                    Todo.append(Children[0][1])\n",
    "                    Todo.append(Children[1][1])\n",
    "                else:\n",
    "                    CForm.append(Children[1][0])\n",
    "                    Todo.append(Children[1][1])\n",
    "                    Todo.append(Children[0][1])\n",
    "            elif len(Children) == 1:\n",
    "                    CForm.append(Children[0][0])\n",
    "                    Todo.append(Children[0][1])\n",
    "#                     CForm.append(-1)\n",
    "            else:\n",
    "#                 CForm.append(-1)\n",
    "#                 CForm.append(-1)\n",
    "                pass\n",
    "        CForms.add(tuple(CForm))\n",
    "#     print \"----------------------\"\n",
    "#     print BranchingNumber\n",
    "#     PrintIter(ChildrenLookup)\n",
    "#     return sorted(CForms)[::-1]\n",
    "    return tuple([x for sublist in sorted(CForms,reverse=True) for x in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageLookup(NodeName):\n",
    "    \"\"\"\n",
    "    :string Nodename:\n",
    "    :return string Filename:\n",
    "    \"\"\"\n",
    "    ID = np.sum(np.reshape(np.array(map(lambda x: np.array(x.split(\",\"), dtype=int), NodeName.split(\" \")[0].split(\";\"))), 6) * [32, 16, 8, 4, 2, 1])\n",
    "\n",
    "    return Images[ID]\n",
    "\n",
    "def imscatter(x, y, image, ax=None, zoom=1, text=False):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if not text:\n",
    "        try:\n",
    "            image = plt.imread(image)\n",
    "        except TypeError:\n",
    "            # Likely already an array...\n",
    "            pass\n",
    "    if text:\n",
    "        im = TextArea(image, minimumdescent=False, textprops=dict(size='large',weight='bold'))\n",
    "        da = DrawingArea(20, 20, 0, 0)\n",
    "        p = Circle((10, 10), 50, color=\"red\")\n",
    "        da.add_artist(p)\n",
    "    else:\n",
    "        im = OffsetImage(image, zoom=zoom)\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    artists = []\n",
    "    for x0, y0 in zip(x, y):\n",
    "        if text:\n",
    "#             ab1 = AnnotationBbox(da, im, (x0, y0), xycoords='data', frameon=False)\n",
    "            ab1 = AnnotationBbox(da, (x0, y0), xycoords='data', frameon=False)\n",
    "            ab2 = AnnotationBbox(im, (x0, y0+9), xycoords='data', frameon=False)\n",
    "#             artists.append(ax.add_artist(ab1))\n",
    "            artists.append(ax.add_artist(ab1))\n",
    "            artists.append(ax.add_artist(ab2))\n",
    "        else:\n",
    "            ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=False)\n",
    "            artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()\n",
    "    return artists\n",
    "\n",
    "def Plot(Graph, with_labels=True, Show=False, pretty_images=False):\n",
    "    Fig = plt.figure()\n",
    "    Axes = Fig.add_subplot(111)\n",
    "    write_dot(Graph,'test.dot')\n",
    "    #Fig.set_title(\"Tree Plot\")\n",
    "    pos=pydot_layout(Graph, prog=\"dot\")\n",
    "    # nx.draw(Graph,pos,with_labels=with_labels,arrows=False, ax=Axes, hold=True)\n",
    "    nx.draw(Graph, pos, with_labels=False, arrows=False, ax=Axes, hold=True, nodeshape = \"o\", width=10.0)\n",
    "\n",
    "    #ZoomSize = 1.8*10**-0\n",
    "    ZoomSize = 0.2\n",
    "    if pretty_images == \"text\":\n",
    "        for NodeName, Loc in pos.items():\n",
    "            imscatter(Loc[0], Loc[1], \"\\n\"*2+NodeName.split(\" \")[0].replace(\";\",\"\\n\"), zoom=ZoomSize, text=True)\n",
    "    elif pretty_images:\n",
    "        for NodeName, Loc in pos.items():\n",
    "            imscatter(Loc[0], Loc[1], \"{}{}\".format('./AllPatterns/', ImageLookup(NodeName)), zoom=ZoomSize)\n",
    "    # Axes.plot(plot_data)\n",
    "    for T in Axes.texts:    # Remove unique node labels.\n",
    "        if T._text.split(\" \")[0] == \"1,0,0;0,0,0\":\n",
    "            T._text = \"1\"\n",
    "        else:\n",
    "            T._text = \"\\n\"*4+T._text.split(\" \")[0].replace(\";\",\"\\n\")\n",
    "    if Show:\n",
    "        plt.show()\n",
    "    return Fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def pretty_time_delta(seconds):\n",
    "    sign_string = '-' if seconds < 0 else ''\n",
    "    seconds = abs(int(seconds))\n",
    "    days, seconds = divmod(seconds, 86400)\n",
    "    hours, seconds = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    if days > 0:\n",
    "        return '%s%dd%dh%dm%ds' % (sign_string, days, hours, minutes, seconds)\n",
    "    elif hours > 0:\n",
    "        return '%s%dh%dm%ds' % (sign_string, hours, minutes, seconds)\n",
    "    elif minutes > 0:\n",
    "        return '%s%dm%ds' % (sign_string, minutes, seconds)\n",
    "    else:\n",
    "        return '%s%ds' % (sign_string, seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def catalan(n):\n",
    "    return int(math.factorial(2*n)/(math.factorial(n+1)*math.factorial(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PathwayFlux(SortedPathways, FluxFunc):\n",
    "    Flux = deque()\n",
    "    for Path in SortedPathways.values():\n",
    "        # By multiplying by the final step normilazation the cancelation will weight the system by the final flux\n",
    "        Flux.append(FluxFunc(Path))\n",
    "    return Flux\n",
    "\n",
    "# def Reactants(P, Reactions, Species):\n",
    "#     PR = deque()\n",
    "#     for R in Reactions:\n",
    "#         PT = (SpeciesToIndex(P, Species) == R[3])\n",
    "#         if PT:\n",
    "#             PR.append((R[0], R[1], R[3]))\n",
    "#     return PR\n",
    "@jit\n",
    "def Reactants(P, Reactions, Species):\n",
    "    ReactionsArray = np.array(Reactions)\n",
    "    PR = deque(map(tuple,ReactionsArray[SpeciesToIndex(P, Species) == ReactionsArray[:,3]][:,(0,1,3)]))\n",
    "    return PR\n",
    "\n",
    "# ReactionsArray = np.array(D.Reactions)\n",
    "# deque(map(tuple,ReactionsArray[5 == ReactionsArray[:,3]][:,(0,1,3)]))\n",
    "\n",
    "@jit\n",
    "def BuildReactionsWithSpeciesInvolvedLookupTables(Data):\n",
    "    LookupTable = dict()\n",
    "    ReactionsArray = np.array(Data.Reactions)\n",
    "    ##  0  1 2 3  4  5 6\n",
    "    ## R1 R2 F P B1 B2 R\n",
    "    for SpeciesRep, SpeciesIndex in Data.SpeciesIndex.items():\n",
    "        LookupTable[SpeciesRep] = deque(map(tuple,ReactionsArray[SpeciesIndex == ReactionsArray[:,3]][:,(0,1,3)]))\n",
    "    return LookupTable\n",
    "\n",
    "def AsmPathways(N=3, Unique = False, Output = False, SaveFiles = False):\n",
    "    process = psutil.Process(os.getpid())\n",
    "    \n",
    "    StartTime = time.time()\n",
    "    ChunkTime = time.time()\n",
    "    D = ImportedData(N)\n",
    "\n",
    "    ReactantsLookup = BuildReactionsWithSpeciesInvolvedLookupTables(D)\n",
    "    \n",
    "    RootNodeName = D.RootNodeName\n",
    "    MonomerName  = D.MonomerName\n",
    "    Tasks = dict()\n",
    "#     Tree = nx.DiGraph()\n",
    "    Tree = Pathway()\n",
    "    Tree.add_node(RootNodeName)\n",
    "    Tasks[Tree] = deque([RootNodeName, ])\n",
    "    SaveGraphs = []\n",
    "    CompletedGraphs = 0\n",
    "#     while np.sum(map(len, Tasks.values())) > 0:\n",
    "#         for Key in [x for x, y in Tasks.items()]:\n",
    "    PreviousStartingTree = Tree\n",
    "    \n",
    "    GraphGCs = []\n",
    "\n",
    "    FileNumber = 1\n",
    "    Current_Round_File = 1\n",
    "    Current_Round_Status = 1\n",
    "    Delta_Output_File   = int(5e5)\n",
    "    Delta_Output_Status = Delta_Output_File\n",
    "    FileList = []\n",
    "    FileListGC = []\n",
    "    while True:\n",
    "        Key = PreviousStartingTree\n",
    "        \n",
    "        try:\n",
    "            LastNode = Tasks[Key].pop()\n",
    "        except:\n",
    "            try:\n",
    "                Key = next(iter(Tasks.iterkeys()))\n",
    "#                 Key = Tasks.keys()[0]\n",
    "            except:\n",
    "                break\n",
    "            LastNode = Tasks[Key].pop()\n",
    "        \n",
    "        G = Key\n",
    "\n",
    "        Rs = ReactantsLookup[LastNode[:D.N*4-1]]\n",
    "\n",
    "        if len(Rs) > 1:\n",
    "            Tree = G.copy()\n",
    "            PreviousDeque = copy.copy(Tasks[G])\n",
    "        for i, R in enumerate(Rs):\n",
    "            \n",
    "            PreviousStartingTree = Key\n",
    "            \n",
    "            if i > 0:\n",
    "                G = Tree.copy()\n",
    "                Tasks[G] = copy.copy(PreviousDeque)\n",
    "\n",
    "            SN1 = D.SpeciesRepList[R[0]]\n",
    "            NodeName1 = UniqueNodeName(G, SN1)\n",
    "\n",
    "            G.add_node(NodeName1)\n",
    "            G.add_edge(LastNode, NodeName1)\n",
    "\n",
    "            SN2 = D.SpeciesRepList[R[1]]\n",
    "            NodeName2 = UniqueNodeName(G, SN2)\n",
    "\n",
    "            G.add_node(NodeName2)\n",
    "            G.add_edge(LastNode, NodeName2)\n",
    "\n",
    "            if SN1 != MonomerName:\n",
    "                Tasks[G].append(NodeName1)\n",
    "            if SN2 != MonomerName:\n",
    "                Tasks[G].append(NodeName2)\n",
    "            \n",
    "            if len(G.nodes()) == D.N*4-1:\n",
    "                CompletedGraphs += 1\n",
    "                del Tasks[G]\n",
    "#                 if len(SaveGraphs) < 10e10:\n",
    "                SaveGraphs.append(G)\n",
    "                \n",
    "                GraphGCs.append(CannonicalIndices(G, D, D.RootNodeName))\n",
    "                \n",
    "                Current_Round_Status += 1\n",
    "                Current_Round_File   += 1\n",
    "                if Output and Current_Round_Status > Delta_Output_Status:\n",
    "                    print \"Time Running: {: >10} | Chunk Time Delta: {: >10} | Graphs found so far: {: >15} | Current SaveGraphs Length: {: >15} | Current Memory Usage: {: >10}\".format(\n",
    "                        pretty_time_delta(time.time() - StartTime),\n",
    "                        pretty_time_delta(time.time() - ChunkTime),\n",
    "                        locale.format(\"%d\",CompletedGraphs, grouping=True),\n",
    "                        locale.format(\"%d\", len(SaveGraphs), grouping=True),\n",
    "                        sizeof_fmt(process.memory_info()[0])\n",
    "                    )\n",
    "                if SaveFiles and Current_Round_File > Delta_Output_File:\n",
    "                    FileName = \"FullPathways{}_Chunk{}.pickle\".format(D.N, FileNumber)\n",
    "                    FileWriteStartTime = time.time()\n",
    "                    with gzip.open(FileName, \"w\") as fh:\n",
    "                        pickle.dump(SaveGraphs[:Delta_Output_File], fh, pickle.HIGHEST_PROTOCOL)\n",
    "                        print \"File: {} written in {: >5}\".format(FileName, pretty_time_delta(time.time() - FileWriteStartTime))\n",
    "                        FileList.append(FileName)\n",
    "                    FileName = \"PathwayGCs{}_Chunk{}.pickle\".format(D.N, FileNumber)\n",
    "                    FileWriteStartTime = time.time()\n",
    "                    del SaveGraphs[:Delta_Output_File]\n",
    "                    with gzip.open(FileName, \"w\") as fh:\n",
    "                        pickle.dump(GraphGCs[:Delta_Output_File], fh, pickle.HIGHEST_PROTOCOL)\n",
    "                        print \"File: {} written in {: >5}\".format(FileName, pretty_time_delta(time.time() - FileWriteStartTime))\n",
    "                        FileListGC.append(FileName)\n",
    "                    del GraphGCs[:Delta_Output_File]\n",
    "                    FileNumber += 1\n",
    "                    Current_Round_File -= Delta_Output_File\n",
    "                if Output and Current_Round_Status > Delta_Output_Status:\n",
    "                    ChunkTime = time.time()\n",
    "                    Current_Round_Status -= Delta_Output_Status\n",
    "                \n",
    "    if SaveFiles:\n",
    "        FileName = \"FullPathways{}_Chunk{}.pickle\".format(D.N, FileNumber)\n",
    "        FileWriteStartTime = time.time()\n",
    "        with gzip.open(FileName, \"w\") as fh:\n",
    "            pickle.dump(SaveGraphs, fh, pickle.HIGHEST_PROTOCOL)\n",
    "            print \"File: {} written in {: >5}\".format(FileName, pretty_time_delta(time.time() - FileWriteStartTime))\n",
    "            FileList.append(FileName)\n",
    "        del SaveGraphs\n",
    "        FileName = \"PathwayGCs{}_Chunk{}.pickle\".format(D.N, FileNumber)\n",
    "        with gzip.open(FileName, \"w\") as fh:\n",
    "            pickle.dump(GraphGCs, fh, pickle.HIGHEST_PROTOCOL)\n",
    "            print \"File: {} written in {: >5}\".format(FileName, pretty_time_delta(time.time() - FileWriteStartTime))\n",
    "            FileListGC.append(FileName)\n",
    "        del GraphGCs\n",
    "\n",
    "        FileNumber += 1\n",
    "                    \n",
    "#                     if D.SpeciesIndex[SN1] != 0:\n",
    "#                         Tasks[G].append(NodeName1)\n",
    "#                     if D.SpeciesIndex[SN2] != 0:\n",
    "#                         Tasks[G].append(NodeName2)\n",
    "#                 Degree = [x for x,y in G.degree().items() if y!=3 and x != D.RootNodeName and x[:D.N*4-1] != D.MonomerName and x not in Tasks[G]]\n",
    "#                 for K in Degree:\n",
    "#                     if Output:\n",
    "#                         print \"Degree Check Used!!! : {}\".format(K)\n",
    "#                     Tasks[G].append(K)\n",
    "\n",
    "#             [Tasks[G].append(x) for x,y in G.degree().items() if y!=3 and x != D.RootNodeName and x[:D.N*4-1] != D.MonomerName and x not in Tasks[G]]\n",
    "\n",
    "#             Degree = G.degree()\n",
    "#             for K in Degree.keys():\n",
    "#                 if K[:D.N*4-1] == RootNodeName:\n",
    "#                     pass\n",
    "#                 elif K[:D.N*4-1] == MonomerName:\n",
    "#                     pass\n",
    "#                 elif Degree[K] != 3 and K not in Tasks[G]:\n",
    "#                     if Output:\n",
    "#                         print \"Degree Check Used!!! : {}\".format(K)\n",
    "#                     Tasks[G].append(K)\n",
    "    \n",
    "    if Output:\n",
    "        print \"-----------------------\"+\"-\"*10\n",
    "        print \"Maximum Possible Trees {: >10}\".format(catalan(D.N*2 - 1))\n",
    "        print \"Full Length Trees:     {: >10}\".format(CompletedGraphs)\n",
    "        if not SaveFiles:\n",
    "            print \"Total Trees Found:     {: >10}\".format(len(SaveGraphs))\n",
    "            print \"Wrong Node Count:      {: >10}\".format(len([x for x in SaveGraphs if len(x.nodes()) != D.N*4-1]))\n",
    "            print \"Wrong Degree Count:    {: >10}\".format(len([x for x,y in G.degree().items() if y!=3 and x != D.RootNodeName and x[:D.N*4-1] != D.MonomerName for G in SaveGraphs]))\n",
    "#         print \"Wrong Degree Count:    {: >10}\".format(len([x for x,y in G.degree().items() if y!=3 and x != D.RootNodeName and x[:D.N*4-1] != D.MonomerName for G in SaveGraphs]))\n",
    "\n",
    "    if not SaveFiles:\n",
    "        return D, SaveGraphs\n",
    "    if SaveFiles:\n",
    "        return D, FileList, FileListGC\n",
    "\n",
    "def UniquifyGraphs(D, SaveGraphs, Output = False):\n",
    "    # Unique Graphs\n",
    "    Graphs = {}\n",
    "    InvalidGraphs = {}\n",
    "    InvalidGraphsCount = {}\n",
    "    \n",
    "#     def InList(L1, L2, Index = False):\n",
    "#         N1 = np.array(L1)\n",
    "#         for k, i in enumerate(L2):\n",
    "#             Ni = np.array(i)\n",
    "#             if (N1 == Ni).all():\n",
    "#                 if Index:\n",
    "#                     return True, k\n",
    "#                 else:\n",
    "#                     return True\n",
    "#         return False\n",
    "#     from numba import njit, prange\n",
    "    \n",
    "    DuplicateCount = 0\n",
    "    GraphGCs = [CannonicalIndices(G, D, D.RootNodeName) for G in SaveGraphs]\n",
    "\n",
    "\n",
    "#     GraphGCSet = set([CannonicalIndices(G, D, RootNodeName) for G in Tasks.keys()])\n",
    "    Match = dict()\n",
    "    for GC in GraphGCs:\n",
    "        try:\n",
    "            Match[len(GC)][tuple(GC[:2])].add(GC)\n",
    "        except:\n",
    "            try:\n",
    "                Match[len(GC)][tuple(GC[:2])]=set([GC])\n",
    "            except:\n",
    "                Match[len(GC)] = dict()\n",
    "                Match[len(GC)][tuple(GC[:2])]=set([GC])\n",
    "    for i, G in enumerate(SaveGraphs):\n",
    "#         GC = CannonicalIndices(G, D, RootNodeName)\n",
    "#         GC = np.array(GC)\n",
    "#         GC = tuple(GC)\n",
    "        GC = GraphGCs[i]\n",
    "        if GC in Match[len(GC)][GC[:2]]:\n",
    "            Graphs[GC]=G\n",
    "#             DuplicateCount += 1\n",
    "#             try:\n",
    "#                 InvalidGraphsCount[GC] += 1\n",
    "#                 InvalidGraphs[GC].append(G)\n",
    "#             except:\n",
    "#                 InvalidGraphsCount[GC] = 2\n",
    "#                 InvalidGraphs[GC] = []\n",
    "#                 InvalidGraphs[GC].append(Graphs[GC])\n",
    "#                 InvalidGraphs[GC].append(G)\n",
    "        \n",
    "    if Output:\n",
    "        print \"Duplicate Trees Found: {: >10}\".format(len(GraphGCs)-len(Graphs))\n",
    "        print \"Unique Trees Found:    {: >10}\".format(len(Graphs.keys()))\n",
    "        print \"-----------------------\"+\"-\"*10\n",
    "#     for x in InvalidGraphsCount.items():\n",
    "#         print x\n",
    "    return OrderedDict([x for x in sorted(Graphs.items(),reverse=True)])\n",
    "#     return D, OrderedDict([x for x in sorted(Graphs.items(),reverse=True)]), OrderedDict([x for x in sorted(InvalidGraphs.items(),reverse=True)])\n",
    "\n",
    "    #for k in Graphs.keys():\n",
    "    #    print InList(k, SortedPathways.keys())\n",
    "def ImportChunks(FileList):\n",
    "    L = list()\n",
    "    for File in FileList:\n",
    "        with gzip.open(File, \"r\") as fh:\n",
    "            L.extend(pickle.load(fh))\n",
    "    return L\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "D3, FullGraphs3 = AsmPathways(3, Output=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "BeforeMemoryUsage = process.memory_info()[0]\n",
    "SortedPathways3 = UniquifyGraphs(D3, FullGraphs3, Output=True)\n",
    "print \"Increase in Memory Usage: {: >8} \\n\".format(sizeof_fmt(process.memory_info()[0] - BeforeMemoryUsage))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "with open(\"FullPathways3.pickle\", \"w\") as fh:\n",
    "    pickle.dump(FullGraphs3, fh, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"UniquePathways3.pickle\", \"w\") as fh:\n",
    "    pickle.dump(SortedPathways3, fh, pickle.HIGHEST_PROTOCOL)\n",
    "del D3\n",
    "del FullGraphs3\n",
    "del SortedPathways3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "D4, FullGraphs4 = AsmPathways(4, Output=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "BeforeMemoryUsage = process.memory_info()[0]\n",
    "SortedPathways4 = UniquifyGraphs(D4, FullGraphs4, Output=True)\n",
    "print \"Increase in Memory Usage: {: >8} \\n\".format(sizeof_fmt(process.memory_info()[0] - BeforeMemoryUsage))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "with open(\"FullPathways4.pickle\", \"w\") as fh:\n",
    "    pickle.dump(FullGraphs4, fh, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"UniquePathways4.pickle\", \"w\") as fh:\n",
    "    pickle.dump(SortedPathways4, fh, pickle.HIGHEST_PROTOCOL)\n",
    "del D4\n",
    "del FullGraphs4\n",
    "del SortedPathways4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "D5, FullGraphs5 = AsmPathways(5, Output=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "BeforeMemoryUsage = process.memory_info()[0]\n",
    "SortedPathways5 = UniquifyGraphs(D5, FullGraphs5, Output=True)\n",
    "print \"Increase in Memory Usage: {: >8} \\n\".format(sizeof_fmt(process.memory_info()[0] - BeforeMemoryUsage))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "with gzip.open(\"FullPathways5.pickle\", \"w\") as fh:\n",
    "    pickle.dump(FullGraphs5, fh, pickle.HIGHEST_PROTOCOL)\n",
    "with gzip.open(\"UniquePathways5.pickle\", \"w\") as fh:\n",
    "    pickle.dump(SortedPathways5, fh, pickle.HIGHEST_PROTOCOL)\n",
    "del D5\n",
    "del FullGraphs5\n",
    "del SortedPathways5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "D6, FullFileList6, GCFileList6 = AsmPathways(6, Output=True, SaveFiles=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "FullGraphs6 = ImportChunks(FullFileList6)\n",
    "D6 = ImportedData(6)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "BeforeMemoryUsage = process.memory_info()[0]\n",
    "SortedPathways6 = UniquifyGraphs(D6, FullGraphs6, Output=True)\n",
    "print \"Increase in Memory Usage: {: >8} \\n\".format(sizeof_fmt(process.memory_info()[0] - BeforeMemoryUsage))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "with gzip.open(\"FullPathways6.pickle\", \"w\") as fh:\n",
    "    pickle.dump(FullGraphs6, fh, pickle.HIGHEST_PROTOCOL)\n",
    "with gzip.open(\"UniquePathways6.pickle\", \"w\") as fh:\n",
    "    pickle.dump(SortedPathways6, fh, pickle.HIGHEST_PROTOCOL)\n",
    "del D6\n",
    "del FullGraphs6\n",
    "del SortedPathways6"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "D6, FullGraphs6 = AsmPathways(6, Output=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "BeforeMemoryUsage = process.memory_info()[0]\n",
    "SortedPathways6 = UniquifyGraphs(D6, FullGraphs6, Output=True)\n",
    "print \"Increase in Memory Usage: {: >8} \\n\".format(sizeof_fmt(process.memory_info()[0] - BeforeMemoryUsage))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "with gzip.open(\"FullPathways6.pickle\", \"w\") as fh:\n",
    "    pickle.dump(FullGraphs6, fh, pickle.HIGHEST_PROTOCOL)\n",
    "with gzip.open(\"UniquePathways6.pickle\", \"w\") as fh:\n",
    "    pickle.dump(SortedPathways6, fh, pickle.HIGHEST_PROTOCOL)\n",
    "del D6\n",
    "del FullGraphs6\n",
    "del SortedPathways6"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "D7, FullFileList7, GCFileList7 = AsmPathways(7, Output=True, SaveFiles=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "BeforeMemoryUsage = process.memory_info()[0]\n",
    "SortedPathways7 = UniquifyGraphs(D7, FullGraphs7, Output=True)\n",
    "print \"Increase in Memory Usage: {: >8} \\n\".format(sizeof_fmt(process.memory_info()[0] - BeforeMemoryUsage))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "with gzip.open(\"FullPathways7.pickle\", \"w\") as fh:\n",
    "    pickle.dump(FullGraphs3, fh, pickle.HIGHEST_PROTOCOL)\n",
    "with gzip.open(\"UniquePathways7.pickle\", \"w\") as fh:\n",
    "    pickle.dump(SortedPathways7, fh, pickle.HIGHEST_PROTOCOL)\n",
    "del D7\n",
    "del FullGraphs7\n",
    "del SortedPathways7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Running:      3m56s | Chunk Time Delta:      3m56s | Graphs found so far:         500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:     6.5GiB\n",
      "File: FullPathways8_Chunk1.pickle written in 2m24s\n",
      "File: PathwayGCs8_Chunk1.pickle written in   19s\n",
      "Time Running:     11m16s | Chunk Time Delta:      4m36s | Graphs found so far:       1,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:     7.9GiB\n",
      "File: FullPathways8_Chunk2.pickle written in 2m17s\n",
      "File: PathwayGCs8_Chunk2.pickle written in   20s\n",
      "Time Running:     21m24s | Chunk Time Delta:      7m29s | Graphs found so far:       1,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:     9.8GiB\n",
      "File: FullPathways8_Chunk3.pickle written in 2m19s\n",
      "File: PathwayGCs8_Chunk3.pickle written in   20s\n",
      "Time Running:     31m23s | Chunk Time Delta:      7m18s | Graphs found so far:       2,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    10.3GiB\n",
      "File: FullPathways8_Chunk4.pickle written in  2m6s\n",
      "File: PathwayGCs8_Chunk4.pickle written in   19s\n",
      "Time Running:      41m2s | Chunk Time Delta:      7m12s | Graphs found so far:       2,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    10.5GiB\n",
      "File: FullPathways8_Chunk5.pickle written in  2m9s\n",
      "File: PathwayGCs8_Chunk5.pickle written in   23s\n",
      "Time Running:     51m23s | Chunk Time Delta:      7m46s | Graphs found so far:       3,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    10.8GiB\n",
      "File: FullPathways8_Chunk6.pickle written in 2m21s\n",
      "File: PathwayGCs8_Chunk6.pickle written in   19s\n",
      "Time Running:     1h3m4s | Chunk Time Delta:      8m59s | Graphs found so far:       3,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    10.9GiB\n",
      "File: FullPathways8_Chunk7.pickle written in 2m17s\n",
      "File: PathwayGCs8_Chunk7.pickle written in   24s\n",
      "Time Running:   1h14m16s | Chunk Time Delta:      8m30s | Graphs found so far:       4,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    11.1GiB\n",
      "File: FullPathways8_Chunk8.pickle written in  2m8s\n",
      "File: PathwayGCs8_Chunk8.pickle written in   21s\n",
      "Time Running:   1h22m43s | Chunk Time Delta:      5m56s | Graphs found so far:       4,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    12.2GiB\n",
      "File: FullPathways8_Chunk9.pickle written in  2m8s\n",
      "File: PathwayGCs8_Chunk9.pickle written in   17s\n",
      "Time Running:   1h33m45s | Chunk Time Delta:      8m35s | Graphs found so far:       5,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    13.5GiB\n",
      "File: FullPathways8_Chunk10.pickle written in 2m28s\n",
      "File: PathwayGCs8_Chunk10.pickle written in   19s\n",
      "Time Running:   1h49m43s | Chunk Time Delta:      13m9s | Graphs found so far:       5,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    15.0GiB\n",
      "File: FullPathways8_Chunk11.pickle written in 2m28s\n",
      "File: PathwayGCs8_Chunk11.pickle written in   22s\n",
      "Time Running:    2h6m49s | Chunk Time Delta:     14m15s | Graphs found so far:       6,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    15.5GiB\n",
      "File: FullPathways8_Chunk12.pickle written in  2m0s\n",
      "File: PathwayGCs8_Chunk12.pickle written in   21s\n",
      "Time Running:   2h21m43s | Chunk Time Delta:     12m32s | Graphs found so far:       6,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    15.6GiB\n",
      "File: FullPathways8_Chunk13.pickle written in  2m7s\n",
      "File: PathwayGCs8_Chunk13.pickle written in   20s\n",
      "Time Running:   2h38m49s | Chunk Time Delta:     14m37s | Graphs found so far:       7,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    15.6GiB\n",
      "File: FullPathways8_Chunk14.pickle written in  2m7s\n",
      "File: PathwayGCs8_Chunk14.pickle written in   22s\n",
      "Time Running:   2h58m52s | Chunk Time Delta:     17m32s | Graphs found so far:       7,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    15.8GiB\n",
      "File: FullPathways8_Chunk15.pickle written in 2m41s\n",
      "File: PathwayGCs8_Chunk15.pickle written in   23s\n",
      "Time Running:    3h20m3s | Chunk Time Delta:      18m6s | Graphs found so far:       8,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.0GiB\n",
      "File: FullPathways8_Chunk16.pickle written in 2m53s\n",
      "File: PathwayGCs8_Chunk16.pickle written in   24s\n",
      "Time Running:   3h40m15s | Chunk Time Delta:     16m54s | Graphs found so far:       8,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.1GiB\n",
      "File: FullPathways8_Chunk17.pickle written in 2m39s\n",
      "File: PathwayGCs8_Chunk17.pickle written in   24s\n",
      "Time Running:    4h1m36s | Chunk Time Delta:     18m15s | Graphs found so far:       9,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.2GiB\n",
      "File: FullPathways8_Chunk18.pickle written in 2m58s\n",
      "File: PathwayGCs8_Chunk18.pickle written in   25s\n",
      "Time Running:    4h22m3s | Chunk Time Delta:      17m2s | Graphs found so far:       9,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.3GiB\n",
      "File: FullPathways8_Chunk19.pickle written in 2m22s\n",
      "File: PathwayGCs8_Chunk19.pickle written in   20s\n",
      "Time Running:   4h38m28s | Chunk Time Delta:     13m41s | Graphs found so far:      10,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.3GiB\n",
      "File: FullPathways8_Chunk20.pickle written in 2m25s\n",
      "File: PathwayGCs8_Chunk20.pickle written in   23s\n",
      "Time Running:   4h56m29s | Chunk Time Delta:     15m12s | Graphs found so far:      10,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.3GiB\n",
      "File: FullPathways8_Chunk21.pickle written in 2m17s\n",
      "File: PathwayGCs8_Chunk21.pickle written in   20s\n",
      "Time Running:   5h16m52s | Chunk Time Delta:     17m44s | Graphs found so far:      11,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.3GiB\n",
      "File: FullPathways8_Chunk22.pickle written in 2m51s\n",
      "File: PathwayGCs8_Chunk22.pickle written in   21s\n",
      "Time Running:   5h37m44s | Chunk Time Delta:     17m38s | Graphs found so far:      11,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.5GiB\n",
      "File: FullPathways8_Chunk23.pickle written in 2m44s\n",
      "File: PathwayGCs8_Chunk23.pickle written in   24s\n",
      "Time Running:    5h59m8s | Chunk Time Delta:     18m14s | Graphs found so far:      12,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.7GiB\n",
      "File: FullPathways8_Chunk24.pickle written in  3m2s\n",
      "File: PathwayGCs8_Chunk24.pickle written in   26s\n",
      "Time Running:   6h22m58s | Chunk Time Delta:     20m20s | Graphs found so far:      12,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk25.pickle written in 3m18s\n",
      "File: PathwayGCs8_Chunk25.pickle written in   30s\n",
      "Time Running:   6h47m14s | Chunk Time Delta:     20m26s | Graphs found so far:      13,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk26.pickle written in 3m17s\n",
      "File: PathwayGCs8_Chunk26.pickle written in   25s\n",
      "Time Running:    7h12m1s | Chunk Time Delta:      21m4s | Graphs found so far:      13,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk27.pickle written in  3m4s\n",
      "File: PathwayGCs8_Chunk27.pickle written in   26s\n",
      "Time Running:    7h36m9s | Chunk Time Delta:     20m36s | Graphs found so far:      14,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk28.pickle written in 2m10s\n",
      "File: PathwayGCs8_Chunk28.pickle written in   23s\n",
      "Time Running:   7h58m36s | Chunk Time Delta:     19m53s | Graphs found so far:      14,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk29.pickle written in 2m53s\n",
      "File: PathwayGCs8_Chunk29.pickle written in   24s\n",
      "Time Running:   8h20m18s | Chunk Time Delta:     18m24s | Graphs found so far:      15,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk30.pickle written in 2m38s\n",
      "File: PathwayGCs8_Chunk30.pickle written in   22s\n",
      "Time Running:   8h41m56s | Chunk Time Delta:     18m36s | Graphs found so far:      15,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk31.pickle written in 2m57s\n",
      "File: PathwayGCs8_Chunk31.pickle written in   21s\n",
      "Time Running:    9h4m52s | Chunk Time Delta:     19m36s | Graphs found so far:      16,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk32.pickle written in 2m35s\n",
      "File: PathwayGCs8_Chunk32.pickle written in   21s\n",
      "Time Running:   9h28m21s | Chunk Time Delta:     20m30s | Graphs found so far:      16,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk33.pickle written in 2m21s\n",
      "File: PathwayGCs8_Chunk33.pickle written in   25s\n",
      "Time Running:   9h49m42s | Chunk Time Delta:     18m34s | Graphs found so far:      17,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk34.pickle written in 2m37s\n",
      "File: PathwayGCs8_Chunk34.pickle written in   22s\n",
      "Time Running:  10h14m58s | Chunk Time Delta:     22m15s | Graphs found so far:      17,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk35.pickle written in 2m20s\n",
      "File: PathwayGCs8_Chunk35.pickle written in   25s\n",
      "Time Running:  10h38m50s | Chunk Time Delta:      21m5s | Graphs found so far:      18,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk36.pickle written in  3m3s\n",
      "File: PathwayGCs8_Chunk36.pickle written in   23s\n",
      "Time Running:   11h4m39s | Chunk Time Delta:     22m21s | Graphs found so far:      18,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk37.pickle written in 2m42s\n",
      "File: PathwayGCs8_Chunk37.pickle written in   25s\n",
      "Time Running:  11h30m40s | Chunk Time Delta:     22m52s | Graphs found so far:      19,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk38.pickle written in 2m48s\n",
      "File: PathwayGCs8_Chunk38.pickle written in   23s\n",
      "Time Running:  11h56m10s | Chunk Time Delta:     22m18s | Graphs found so far:      19,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk39.pickle written in 2m29s\n",
      "File: PathwayGCs8_Chunk39.pickle written in   21s\n",
      "Time Running:  12h19m57s | Chunk Time Delta:     20m56s | Graphs found so far:      20,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk40.pickle written in 2m28s\n",
      "File: PathwayGCs8_Chunk40.pickle written in   24s\n",
      "Time Running:  12h45m39s | Chunk Time Delta:     22m48s | Graphs found so far:      20,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk41.pickle written in 2m38s\n",
      "File: PathwayGCs8_Chunk41.pickle written in   23s\n",
      "Time Running:  13h10m47s | Chunk Time Delta:      22m5s | Graphs found so far:      21,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk42.pickle written in 2m33s\n",
      "File: PathwayGCs8_Chunk42.pickle written in   21s\n",
      "Time Running:  13h30m55s | Chunk Time Delta:     17m13s | Graphs found so far:      21,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk43.pickle written in 2m10s\n",
      "File: PathwayGCs8_Chunk43.pickle written in   21s\n",
      "Time Running:  13h54m18s | Chunk Time Delta:     20m51s | Graphs found so far:      22,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk44.pickle written in  3m4s\n",
      "File: PathwayGCs8_Chunk44.pickle written in   22s\n",
      "Time Running:  14h21m53s | Chunk Time Delta:      24m7s | Graphs found so far:      22,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk45.pickle written in 2m30s\n",
      "File: PathwayGCs8_Chunk45.pickle written in   26s\n",
      "Time Running:  14h50m37s | Chunk Time Delta:     25m47s | Graphs found so far:      23,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk46.pickle written in 2m53s\n",
      "File: PathwayGCs8_Chunk46.pickle written in   26s\n",
      "Time Running:  15h17m50s | Chunk Time Delta:     23m52s | Graphs found so far:      23,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk47.pickle written in 2m45s\n",
      "File: PathwayGCs8_Chunk47.pickle written in   26s\n",
      "Time Running:  15h46m19s | Chunk Time Delta:     25m16s | Graphs found so far:      24,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk48.pickle written in 2m24s\n",
      "File: PathwayGCs8_Chunk48.pickle written in   21s\n",
      "Time Running:  16h15m16s | Chunk Time Delta:     26m10s | Graphs found so far:      24,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk49.pickle written in 2m49s\n",
      "File: PathwayGCs8_Chunk49.pickle written in   23s\n",
      "Time Running:   16h44m6s | Chunk Time Delta:     25m37s | Graphs found so far:      25,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk50.pickle written in 2m23s\n",
      "File: PathwayGCs8_Chunk50.pickle written in   24s\n",
      "Time Running:  17h12m42s | Chunk Time Delta:     25m46s | Graphs found so far:      25,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk51.pickle written in  3m6s\n",
      "File: PathwayGCs8_Chunk51.pickle written in   25s\n",
      "Time Running:   17h41m7s | Chunk Time Delta:     24m52s | Graphs found so far:      26,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk52.pickle written in 2m50s\n",
      "File: PathwayGCs8_Chunk52.pickle written in   23s\n",
      "Time Running:   18h7m47s | Chunk Time Delta:     23m25s | Graphs found so far:      26,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk53.pickle written in 2m27s\n",
      "File: PathwayGCs8_Chunk53.pickle written in   23s\n",
      "Time Running:  18h27m59s | Chunk Time Delta:     17m21s | Graphs found so far:      27,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk54.pickle written in 2m53s\n",
      "File: PathwayGCs8_Chunk54.pickle written in   22s\n",
      "Time Running:  18h52m43s | Chunk Time Delta:     21m27s | Graphs found so far:      27,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk55.pickle written in 2m35s\n",
      "File: PathwayGCs8_Chunk55.pickle written in   19s\n",
      "Time Running:  19h14m39s | Chunk Time Delta:      19m1s | Graphs found so far:      28,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk56.pickle written in 3m11s\n",
      "File: PathwayGCs8_Chunk56.pickle written in   22s\n",
      "Time Running:  19h39m51s | Chunk Time Delta:     21m37s | Graphs found so far:      28,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk57.pickle written in  3m5s\n",
      "File: PathwayGCs8_Chunk57.pickle written in   22s\n",
      "Time Running:   20h6m31s | Chunk Time Delta:     23m11s | Graphs found so far:      29,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk58.pickle written in 3m18s\n",
      "File: PathwayGCs8_Chunk58.pickle written in   23s\n",
      "Time Running:   20h35m8s | Chunk Time Delta:     24m54s | Graphs found so far:      29,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk59.pickle written in 2m50s\n",
      "File: PathwayGCs8_Chunk59.pickle written in   22s\n",
      "Time Running:   21h1m23s | Chunk Time Delta:      23m1s | Graphs found so far:      30,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk60.pickle written in 2m33s\n",
      "File: PathwayGCs8_Chunk60.pickle written in   20s\n",
      "Time Running:  21h30m59s | Chunk Time Delta:     26m41s | Graphs found so far:      30,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk61.pickle written in 3m10s\n",
      "File: PathwayGCs8_Chunk61.pickle written in   25s\n",
      "Time Running:    22h1m1s | Chunk Time Delta:     26m24s | Graphs found so far:      31,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk62.pickle written in 3m21s\n",
      "File: PathwayGCs8_Chunk62.pickle written in   22s\n",
      "Time Running:  22h32m37s | Chunk Time Delta:     27m52s | Graphs found so far:      31,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk63.pickle written in 2m56s\n",
      "File: PathwayGCs8_Chunk63.pickle written in   22s\n",
      "Time Running:  22h59m49s | Chunk Time Delta:     23m52s | Graphs found so far:      32,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk64.pickle written in 2m38s\n",
      "File: PathwayGCs8_Chunk64.pickle written in   25s\n",
      "Time Running:  23h27m52s | Chunk Time Delta:     24m59s | Graphs found so far:      32,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk65.pickle written in  2m7s\n",
      "File: PathwayGCs8_Chunk65.pickle written in   22s\n",
      "Time Running:  23h55m50s | Chunk Time Delta:     25m26s | Graphs found so far:      33,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk66.pickle written in 2m45s\n",
      "File: PathwayGCs8_Chunk66.pickle written in   22s\n",
      "Time Running: 1d0h23m12s | Chunk Time Delta:     24m14s | Graphs found so far:      33,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk67.pickle written in 2m23s\n",
      "File: PathwayGCs8_Chunk67.pickle written in   22s\n",
      "Time Running:  1d0h49m2s | Chunk Time Delta:      23m2s | Graphs found so far:      34,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk68.pickle written in 2m24s\n",
      "File: PathwayGCs8_Chunk68.pickle written in   20s\n",
      "Time Running: 1d1h15m45s | Chunk Time Delta:     23m58s | Graphs found so far:      34,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk69.pickle written in 2m36s\n",
      "File: PathwayGCs8_Chunk69.pickle written in   18s\n",
      "Time Running:  1d1h44m0s | Chunk Time Delta:     25m20s | Graphs found so far:      35,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk70.pickle written in 2m45s\n",
      "File: PathwayGCs8_Chunk70.pickle written in   20s\n",
      "Time Running: 1d2h11m29s | Chunk Time Delta:     24m23s | Graphs found so far:      35,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk71.pickle written in 2m48s\n",
      "File: PathwayGCs8_Chunk71.pickle written in   26s\n",
      "Time Running:  1d2h37m9s | Chunk Time Delta:     22m25s | Graphs found so far:      36,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk72.pickle written in 2m19s\n",
      "File: PathwayGCs8_Chunk72.pickle written in   23s\n",
      "Time Running:   1d3h3m1s | Chunk Time Delta:      23m8s | Graphs found so far:      36,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk73.pickle written in 2m42s\n",
      "File: PathwayGCs8_Chunk73.pickle written in   23s\n",
      "Time Running:  1d3h29m3s | Chunk Time Delta:     22m56s | Graphs found so far:      37,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk74.pickle written in  3m9s\n",
      "File: PathwayGCs8_Chunk74.pickle written in   20s\n",
      "Time Running: 1d3h55m19s | Chunk Time Delta:     22m45s | Graphs found so far:      37,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk75.pickle written in 2m15s\n",
      "File: PathwayGCs8_Chunk75.pickle written in   22s\n",
      "Time Running: 1d4h26m10s | Chunk Time Delta:     28m13s | Graphs found so far:      38,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk76.pickle written in 2m32s\n",
      "File: PathwayGCs8_Chunk76.pickle written in   27s\n",
      "Time Running: 1d4h57m11s | Chunk Time Delta:      28m1s | Graphs found so far:      38,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk77.pickle written in 2m53s\n",
      "File: PathwayGCs8_Chunk77.pickle written in   24s\n",
      "Time Running: 1d5h29m16s | Chunk Time Delta:     28m46s | Graphs found so far:      39,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk78.pickle written in 2m42s\n",
      "File: PathwayGCs8_Chunk78.pickle written in   28s\n",
      "Time Running:  1d6h0m29s | Chunk Time Delta:      28m2s | Graphs found so far:      39,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk79.pickle written in  3m5s\n",
      "File: PathwayGCs8_Chunk79.pickle written in   26s\n",
      "Time Running: 1d6h31m43s | Chunk Time Delta:     27m42s | Graphs found so far:      40,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk80.pickle written in 3m14s\n",
      "File: PathwayGCs8_Chunk80.pickle written in   23s\n",
      "Time Running:  1d7h3m41s | Chunk Time Delta:     28m20s | Graphs found so far:      40,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk81.pickle written in 2m39s\n",
      "File: PathwayGCs8_Chunk81.pickle written in   31s\n",
      "Time Running: 1d7h35m59s | Chunk Time Delta:      29m7s | Graphs found so far:      41,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk82.pickle written in  3m0s\n",
      "File: PathwayGCs8_Chunk82.pickle written in   28s\n",
      "Time Running:  1d8h4m19s | Chunk Time Delta:     24m50s | Graphs found so far:      41,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk83.pickle written in  3m9s\n",
      "File: PathwayGCs8_Chunk83.pickle written in   24s\n",
      "Time Running: 1d8h31m25s | Chunk Time Delta:     23m32s | Graphs found so far:      42,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk84.pickle written in 2m22s\n",
      "File: PathwayGCs8_Chunk84.pickle written in   23s\n",
      "Time Running: 1d8h56m54s | Chunk Time Delta:     22m41s | Graphs found so far:      42,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk85.pickle written in 2m12s\n",
      "File: PathwayGCs8_Chunk85.pickle written in   24s\n",
      "Time Running:  1d9h19m7s | Chunk Time Delta:     19m35s | Graphs found so far:      43,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk86.pickle written in 2m33s\n",
      "File: PathwayGCs8_Chunk86.pickle written in   21s\n",
      "Time Running: 1d9h45m13s | Chunk Time Delta:     23m11s | Graphs found so far:      43,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk87.pickle written in 2m24s\n",
      "File: PathwayGCs8_Chunk87.pickle written in   23s\n",
      "Time Running: 1d10h14m5s | Chunk Time Delta:      26m3s | Graphs found so far:      44,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk88.pickle written in 2m45s\n",
      "File: PathwayGCs8_Chunk88.pickle written in   22s\n",
      "Time Running: 1d10h43m5s | Chunk Time Delta:     25m51s | Graphs found so far:      44,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk89.pickle written in 2m42s\n",
      "File: PathwayGCs8_Chunk89.pickle written in   25s\n",
      "Time Running: 1d11h11m59s | Chunk Time Delta:     25m45s | Graphs found so far:      45,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk90.pickle written in 2m24s\n",
      "File: PathwayGCs8_Chunk90.pickle written in   23s\n",
      "Time Running: 1d11h41m15s | Chunk Time Delta:     26m28s | Graphs found so far:      45,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk91.pickle written in  3m0s\n",
      "File: PathwayGCs8_Chunk91.pickle written in   26s\n",
      "Time Running: 1d12h10m16s | Chunk Time Delta:     25m33s | Graphs found so far:      46,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk92.pickle written in 2m56s\n",
      "File: PathwayGCs8_Chunk92.pickle written in   23s\n",
      "Time Running: 1d12h39m53s | Chunk Time Delta:     26m16s | Graphs found so far:      46,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk93.pickle written in 2m55s\n",
      "File: PathwayGCs8_Chunk93.pickle written in   24s\n",
      "Time Running: 1d13h6m42s | Chunk Time Delta:     23m29s | Graphs found so far:      47,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk94.pickle written in 2m10s\n",
      "File: PathwayGCs8_Chunk94.pickle written in   21s\n",
      "Time Running: 1d13h32m54s | Chunk Time Delta:     23m39s | Graphs found so far:      47,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk95.pickle written in  2m0s\n",
      "File: PathwayGCs8_Chunk95.pickle written in   20s\n",
      "Time Running: 1d13h58m35s | Chunk Time Delta:     23m19s | Graphs found so far:      48,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk96.pickle written in 2m24s\n",
      "File: PathwayGCs8_Chunk96.pickle written in   23s\n",
      "Time Running: 1d14h24m38s | Chunk Time Delta:     23m14s | Graphs found so far:      48,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk97.pickle written in  3m8s\n",
      "File: PathwayGCs8_Chunk97.pickle written in   23s\n",
      "Time Running: 1d14h51m52s | Chunk Time Delta:     23m41s | Graphs found so far:      49,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk98.pickle written in 2m49s\n",
      "File: PathwayGCs8_Chunk98.pickle written in   24s\n",
      "Time Running: 1d15h19m14s | Chunk Time Delta:      24m7s | Graphs found so far:      49,500,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk99.pickle written in 2m22s\n",
      "File: PathwayGCs8_Chunk99.pickle written in   20s\n",
      "Time Running: 1d15h47m20s | Chunk Time Delta:     25m21s | Graphs found so far:      50,000,000 | Current SaveGraphs Length:         500,000 | Current Memory Usage:    16.8GiB\n",
      "File: FullPathways8_Chunk100.pickle written in 2m44s\n",
      "File: PathwayGCs8_Chunk100.pickle written in   23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D8, FullFileList8, GCFileList8 = AsmPathways(8, Output=True, SaveFiles=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "BeforeMemoryUsage = process.memory_info()[0]\n",
    "SortedPathways8 = UniquifyGraphs(D8, FullGraphs8, Output=True)\n",
    "print \"Increase in Memory Usage: {: >8} \\n\".format(sizeof_fmt(process.memory_info()[0] - BeforeMemoryUsage))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "with gzip.open(\"FullPathways8.pickle\", \"w\") as fh:\n",
    "    pickle.dump(FullGraphs8, fh, pickle.HIGHEST_PROTOCOL)\n",
    "with gzip.open(\"UniquePathways8.pickle\", \"w\") as fh:\n",
    "    pickle.dump(SortedPathways8, fh, pickle.HIGHEST_PROTOCOL)\n",
    "del D8\n",
    "del FullGraphs8\n",
    "del SortedPathways8"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time\n",
    "with gzip.open(\"FullPathways5.pickle\", \"r\") as fh:\n",
    "    T1 = pickle.load(fh)\n",
    "with gzip.open(\"UniquePathways5.pickle\", \"r\") as fh:\n",
    "    T2 = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "del T1\n",
    "del T2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "# %lprun -f D.ReactionValue AsmPathways(4)\n",
    "%lprun -f AsmPathways AsmPathways(5, Output=True, SaveFiles=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NonUniqueGraphs = [\"{} : {}\".format(len(x[1]),x[0]) for x in InvalidGraphs.items()]\n",
    "PrintIter(NonUniqueGraphs)\n",
    "print \"\\n\"\n",
    "# PrintIter(SortedPathways.keys())\n",
    "PathwayNodeCount = [\"{} : {} : {}\".format(len(x[1].nodes()), len(x[0]), x[0]) for x in SortedPathways.items()]\n",
    "PrintIter(PathwayNodeCount)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OutputGraphs = True\n",
    "# print mpl.rcParams\n",
    "# InvalidGraphs\n",
    "print(len(SortedPathways7.values()))\n",
    "if OutputGraphs:\n",
    "    for i, Key in enumerate(SortedPathways7.values()[-5:]):\n",
    "        NewTree = nx.DiGraph()\n",
    "        NewTree.add_nodes_from(Key.nodes(data=False))\n",
    "        for Edge in Key.edges():\n",
    "            NewTree.add_edge(Edge[0], Edge[1])\n",
    "            \n",
    "        F = Plot(\n",
    "            NewTree,\n",
    "            Show=True,\n",
    "            pretty_images=\"text\"\n",
    "            )\n",
    "#         F.savefig(\"./Images/UniquePathway{}.pdf\".format(i+1), \n",
    "#                             bbox_inches = 'tight',\n",
    "#                             transparent=True,\n",
    "#                             #dpi = 2400\n",
    "#                             #dpi = 'figure'\n",
    "#                             )\n",
    "        plt.close(F)\n",
    "        del F"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def LeftRight(N1, N2, Graph, Data):\n",
    "    R1 = Graph.node[N1][\"RIndex\"]\n",
    "    R2 = Graph.node[N2][\"RIndex\"]\n",
    "    if R1 > R2:\n",
    "        return N1, N2\n",
    "    elif R1 < R2:\n",
    "        return N2, N1\n",
    "    elif R1 == R2:\n",
    "        R1 = CannonicalGraph(Graph, Data, Start = N1).values()\n",
    "        R2 = CannonicalGraph(Graph, Data, Start = N2).values()\n",
    "        for i in range(max(len(R1), len(R2))):\n",
    "            try:\n",
    "                if R1[i] > R2[i]:\n",
    "                    return N1, N2\n",
    "                if R1[i] < R2[i]:\n",
    "                    return N2, N1\n",
    "            except Exception as e:\n",
    "                print e\n",
    "                if len(R1) > len(R2):\n",
    "                    return N1, N2\n",
    "                elif len(R2) > len(R1):\n",
    "                    return N2, N1\n",
    "            return N1, N2\n",
    "\n",
    "# def CannonicalGraph(Graph, Data, Start):\n",
    "#     map(lambda i: Data.ReactionValue(i, Graph), Graph.nodes())\n",
    "#     return frozenset(Graph.nodes())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import itertools\n",
    "# def NodeConvert(NodeName, Data):\n",
    "#     IntValue = Data.SpeciesIndex[NodeName[:Data.N*4-1]]\n",
    "#     return (IntValue, NodeName)\n",
    "\n",
    "# def ChildrenValues(Node, Graph, Data):\n",
    "#     Children = Graph.succ[Node].keys()\n",
    "# #     return sorted([(Data.SpeciesIndex[NodeName[:Data.N*4-1]], NodeName) for NodeName in Children if Data.SpeciesIndex[NodeName[:Data.N*4-1]] != 0])\n",
    "#     return sorted([NodeName for NodeName in Children if Data.SpeciesIndex[NodeName[:Data.N*4-1]] != 0])\n",
    "\n",
    "# def CannonicalIndices(Graph, Data, Start):\n",
    "#     map(lambda i: Data.ReactionValue(i, Graph), Graph.nodes())\n",
    "# #     AddReactionDataToGraph(Graph, Data)\n",
    "#     StartNodeInt = NodeConvert(Start, Data)[0]\n",
    "# #     NodesAtDepthN = OrderedDict()\n",
    "#     NodesAtDepthI = [[Start]]\n",
    "#     CForms = []\n",
    "#     MaxNonLeafNodes = Data.N-1\n",
    "#     Todo = deque()\n",
    "#     Depth = 0\n",
    "#     while True:\n",
    "#         NodesAtCurrentDepth = NodesAtDepthI[-1]\n",
    "# #         print list(itertools.chain.from_iterable(NodesAtCurrentDepth))\n",
    "#         ChildrenOfNodesAtCurrentDepth = []\n",
    "#         try:\n",
    "#             ChildrenOfNodesAtCurrentDepth.extend(ChildrenValues(NodesAtCurrentDepth, Graph, Data))\n",
    "#         except:\n",
    "#             ChildrenOfNodesAtCurrentDepth.extend([ChildrenValues(Node, Graph, Data) for Node in NodesAtCurrentDepth])\n",
    "            \n",
    "#         print ChildrenOfNodesAtCurrentDepth\n",
    "#         NodesAtDepthI.append(ChildrenOfNodesAtCurrentDepth)\n",
    "#         Depth += 1\n",
    "#         if len(ChildrenOfNodesAtCurrentDepth) ==0:\n",
    "#             break\n",
    "# #             ChildrenOfNodesAtCurrentDepth = [ChildrenValues(Node, Graph, Data) for Node in list(itertools.chain.from_iterable(NodesAtCurrentDepth))]\n",
    "# #         Children = ChildrenValues(CNode, Graph, Data)\n",
    "# #             AddNext(Children[0], Index, True, True)\n",
    "# #             AddNext(Children[1], Index, True, False)\n",
    "#     return NodesAtDepthN\n",
    "\n",
    "# def NodeConvert(NodeName, Data):\n",
    "#     IntValue = Data.SpeciesIndex[NodeName[:Data.N*4-1]]\n",
    "#     return (IntValue, NodeName)\n",
    "\n",
    "# def ChildrenValues(Node, Graph, Data):\n",
    "#     Children = Graph.succ[Node].keys()\n",
    "#     return [(Data.SpeciesIndex[NodeName[:Data.N*4-1]], NodeName) for NodeName in Children if Data.SpeciesIndex[NodeName[:Data.N*4-1]] != 0]\n",
    "# #     return sorted([NodeName for NodeName in Children if Data.SpeciesIndex[NodeName[:Data.N*4-1]] != 0])\n",
    "\n",
    "# def CannonicalIndices(Graph, Data, Start):\n",
    "#     map(lambda i: Data.ReactionValue(i, Graph), Graph.nodes())\n",
    "#     StartNodeInt = NodeConvert(Start, Data)[0]\n",
    "#     CForms = [[],]\n",
    "#     Todo = deque()\n",
    "#     Todo.append((Start,0))\n",
    "#     MaxNonLeafNodes = Data.N-1\n",
    "#     def AddNext(Child, Index, Two, ParentNode):\n",
    "#         if Two:\n",
    "#             CForms.extend(CForms)\n",
    "#             [Todo.append((Child[0][1],I)) for I in range(len(CForms)/2)]\n",
    "#             [Todo.append((Child[1][1],I)) for I in range(len(CForms)/2,len(CForms))]\n",
    "# #             [CForms[I].append(Child[0][0]) for I in range(len(CForms)/2)]\n",
    "# #             [CForms[I].append(Child[1][0]) for I in range(len(CForms)/2,len(CForms))]\n",
    "# #             CForms[Index].append(Child[0][0])\n",
    "# #             CForms[2*Index].append(Child[1][0])\n",
    "#         else:\n",
    "# #             [CForms[I].append(Child[0][0]) for I in range(len(CForms))]\n",
    "# #             CForms[Index].append(Child[0][0])\n",
    "#             [Todo.append((Child[0][1],I)) for I in range(len(CForms))]\n",
    "            \n",
    "# #         if Two:\n",
    "# #             CForms.append([])\n",
    "# #             Index = len(CForms)-1\n",
    "# #             CForms[Index].extend(PreCForm)\n",
    "# #             Todo.append((Child[1],Index,CForms[Index]))\n",
    "# #     while (np.array(map(len,CForms)) < MaxNonLeafNodes).any():\n",
    "#     while len(Todo) > 0:\n",
    "#         print Todo\n",
    "\n",
    "#         CNode, Index = Todo.pop()\n",
    "#         Children = ChildrenValues(CNode, Graph, Data)\n",
    "        \n",
    "#         print Children\n",
    "#         print CForms\n",
    "#         print CNode\n",
    "#         print \"----------------------\"\n",
    "#         ParentNode = NodeConvert(CNode,Data)[0]\n",
    "# #         CForms[Index].append(NodeConvert(CNode,Data)[0])\n",
    "# #         CForms[Index].append(ParentNode)\n",
    "#         CForms[Index].append(CNode)\n",
    "    \n",
    "#         PreCForm = CForms[Index]\n",
    "#         if len(Children) == 2:\n",
    "#             AddNext(Children, Index, True, ParentNode)\n",
    "# #             MonomerCount = len(CNode.split(\"1\"))-1\n",
    "# #             AddNext(Children[1], Index, PreCForm)\n",
    "# #             AddNext(Children[0], \"New\", PreCForm)\n",
    "#         elif len(Children) == 1:\n",
    "#             AddNext(Children, Index, False, ParentNode)\n",
    "# #             CForms[Index].append(-1)\n",
    "#         else:\n",
    "# #             CForms[Index].append(-1)\n",
    "# #             CForms[Index].append(-1)\n",
    "#             pass\n",
    "#     return CForms\n",
    "\n",
    "# def CannonicalIndices(Graph, Data, Start):\n",
    "#     map(lambda i: Data.ReactionValue(i, Graph), Graph.nodes())\n",
    "#     StartNodeInt = NodeConvert(Start, Data)[0]\n",
    "#     CForms = [[],]\n",
    "#     Todo = deque()\n",
    "#     Todo.append((Start,0))\n",
    "#     MaxNonLeafNodes = Data.N-1\n",
    "#     def AddNext(Child, Index, Two, ParentNode):\n",
    "#         if Two:\n",
    "#             CForms.extend(CForms)\n",
    "#             Todo.append((Child[0][1],Index))\n",
    "#             [Todo.append((Child[1][1],I)) for I in range(len(CForms)) if I != Index]\n",
    "# #             [Todo.append((Child[0][1],I)) for I in range(len(CForms)/2)]\n",
    "# #             [Todo.append((Child[1][1],I)) for I in range(len(CForms)/2,len(CForms))]\n",
    "#         else:\n",
    "#             Todo.append((Child[0][1],Index))\n",
    "# #             [Todo.append((Child[0][1],I)) for I in range(len(CForms))]\n",
    "            \n",
    "#     while len(Todo) > 0:\n",
    "#         print Todo\n",
    "\n",
    "#         CNode, Index = Todo.pop()\n",
    "#         Children = ChildrenValues(CNode, Graph, Data)\n",
    "        \n",
    "#         print Children\n",
    "#         print CForms\n",
    "#         print CNode\n",
    "#         print \"----------------------\"\n",
    "#         ParentNode = NodeConvert(CNode,Data)[0]\n",
    "#         CForms[Index].append(ParentNode)\n",
    "    \n",
    "#         PreCForm = CForms[Index]\n",
    "#         if len(Children) == 2:\n",
    "#             AddNext(Children, Index, True, ParentNode)\n",
    "#         elif len(Children) == 1:\n",
    "#             AddNext(Children, Index, False, ParentNode)\n",
    "#         else:\n",
    "#             pass\n",
    "#     return CForms\n",
    "\n",
    "import itertools\n",
    "\n",
    "def NodeConvert(NodeName, Data):\n",
    "    IntValue = Data.SpeciesIndex[NodeName[:Data.N*4-1]]\n",
    "    return (IntValue, NodeName)\n",
    "\n",
    "def ChildrenValues(Node, Graph, Data):\n",
    "    Children = Graph.succ[Node].keys()\n",
    "    return sorted([(Data.SpeciesIndex[NodeName[:Data.N*4-1]], NodeName) for NodeName in Children if Data.SpeciesIndex[NodeName[:Data.N*4-1]] != 0])\n",
    "\n",
    "def CannonicalIndices(Graph, Data, Start):\n",
    "    map(lambda i: Data.ReactionValue(i, Graph), Graph.nodes())\n",
    "    \n",
    "    CForms = set()\n",
    "    StartNodeInt = NodeConvert(Start, Data)[0]\n",
    "    \n",
    "    BranchingNumber = 0\n",
    "    ChildrenLookup = dict()\n",
    "    BranchingChildren = dict()\n",
    "    for Node in Graph.nodes():\n",
    "        ChildrenLookup[Node] = ChildrenValues(Node, Graph, Data)\n",
    "        if len(ChildrenLookup[Node]) == 2:\n",
    "            BranchingChildren[Node] = ChildrenLookup[Node]\n",
    "            BranchingNumber += 1\n",
    "    BranchingNumber = len(BranchingChildren.keys())\n",
    "    \n",
    "    # Left Right Branching True = Left False = Right\n",
    "    Combinations = [x for x in itertools.combinations_with_replacement((True,False),BranchingNumber)]\n",
    "#     PrintIter(BranchingChildren)\n",
    "#     PrintIter(Combinations)\n",
    "    for C in Combinations:\n",
    "        C = deque(C)\n",
    "        Todo = deque()\n",
    "        Todo.append(Start)\n",
    "        CForm = []\n",
    "        while len(Todo) > 0:\n",
    "            CNode = Todo.pop()\n",
    "            Children = ChildrenLookup[CNode]\n",
    "            if len(Children) == 2:\n",
    "                Branch = C.pop()\n",
    "                if Branch:\n",
    "                    CForm.append(Children[0][0])\n",
    "                    Todo.append(Children[0][1])\n",
    "                    Todo.append(Children[1][1])\n",
    "                else:\n",
    "                    CForm.append(Children[1][0])\n",
    "                    Todo.append(Children[1][1])\n",
    "                    Todo.append(Children[0][1])\n",
    "            elif len(Children) == 1:\n",
    "                    CForm.append(Children[0][0])\n",
    "                    Todo.append(Children[0][1])\n",
    "#                     CForm.append(-1)\n",
    "            else:\n",
    "#                 CForm.append(-1)\n",
    "#                 CForm.append(-1)\n",
    "                pass\n",
    "        CForms.add(tuple(CForm))\n",
    "#     print \"----------------------\"\n",
    "#     print BranchingNumber\n",
    "#     PrintIter(ChildrenLookup)\n",
    "#     return sorted(CForms)[::-1]\n",
    "    return tuple([x for sublist in sorted(CForms)[::-1] for x in sublist])\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len('1,1,1,1;0,0,0,0'.split(\"1\"))\n",
    "C = SortedPathways.values()[1]\n",
    "Start = D.RootNodeName"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PrintIter(CannonicalIndices(C, D, Start))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%timeit CannonicalIndices(C, D, Start)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ChildrenValues('1,1,0,0;0,0,0,0 440', C, D)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(21, '1,1,1,1;0,0,0,0 26')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data = D\n",
    "Start = '1,1,1,1;1,1,1,1'\n",
    "CForms = [[1,3,2],[2,4,5,6]]\n",
    "MaxNodes = Data.N*2-1\n",
    "print np.array(map(len,CForms)) < 15\n",
    "[NodeConvert(x,D) for x in C.succ[Start].keys()]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "T = SortedPathways.values()[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "T.nodes()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "D.SpeciesIndex"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A = SpeciesToArrays(SpeciesToRepString(10))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "SpeciesToRepString(A)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print type(A)==np.ndarray\n",
    "print A\n",
    "print A[::-1]\n",
    "print np.roll(A, 1)\n",
    "print SpeciesToRepString(A)\n",
    "print SpeciesToRepString(A[::-1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SpeciesInt = 7\n",
    "CurS = Symmetries(SpeciesInt, Unique=False)\n",
    "print(\"---------------------\")\n",
    "for x in CurS:\n",
    "    print(\"{:=4} : {}\".format(SpeciesArrayToInt(x),x))\n",
    "CurS = Symmetries(SpeciesInt, Unique=True)\n",
    "print(\"---------------------\")\n",
    "for x in CurS:\n",
    "    print(\"{:=4} : {}\".format(SpeciesArrayToInt(x),x))    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SpeciesToRepString(6)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "N = 3\n",
    "print SpeciesToRepString(2**(2*N)-1)\n",
    "print SpeciesToRepString(2**(2*N-1))\n",
    "SpeciesToRepString(2**(2*N-1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "T = InvalidGraphs.items()[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SortedPathways[T[0]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "range(1,N)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for Graphs in InvalidGraphs.items():\n",
    "    print(Graphs[0])\n",
    "    for Graph in Graphs[1]:\n",
    "        Plot(\n",
    "            Graph,\n",
    "            Show=True,\n",
    "            pretty_images=\"text\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%timeit Symmetries(31, Unique=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "D.Species.keys()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(np.array([Symmetries(x, Unique=False) for x in T]).flatten())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.array([Symmetries(D.Species.keys()[x], Ints=True, Unique=False) for x in range(len(D.Species.keys()))]).flatten()\n",
    "D.SpeciesNumbers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[SpeciesToRepString(x) for x in D.SpeciesNumbers]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "D.SpeciesNumberLookup(54)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SpeciesToRepString(63)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "T = D.Reactions[0]\n",
    "D.ReactionRelations(T)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# [[map(D.SpeciesNumberLookup, k) for k in Symmetries(36, Unique=True, Ints=True)]]\n",
    "\n",
    "for Rec in D.Reactions:\n",
    "    Rs = D.ReactionRelations(Rec)\n",
    "    print Rs\n",
    "    for Sym in [Symmetries(R, Unique=False, Ints=True) for R in Rs]:\n",
    "        print Sym\n",
    "        \n",
    "    \n",
    "    #print [SpeciesToRepString(x) for x in map(D.SpeciesNumberLookup, D.ReactionRelations(Rec))]\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "D.SpeciesNumberLookup(7)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def KnownStructureCheck(self, Entry):\n",
    "    if np.sum(D.SpeciesNumbers == SpeciesArrayToInt(Entry)) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def Children(self, Parent, Child):\n",
    "    '''\n",
    "    Parent : int\n",
    "    Child1 : int\n",
    "    Child2 : int\n",
    "    '''\n",
    "    PAS = np.array(Symmetries(Parent, Unique=False, Ints=True, Sorted=True))\n",
    "    C1S = np.array(Symmetries(Child, Unique=False, Ints=True, Sorted=True))\n",
    "    PI  = np.argmax(PAS == Parent)\n",
    "    PC  = PAS[PI]\n",
    "    I = 0\n",
    "    while True:\n",
    "        C1C = C1S[PI + I]\n",
    "        PA = SpeciesToArrays(PC)\n",
    "        C1 = SpeciesToArrays(C1C)\n",
    "        C2 = PA - C1\n",
    "        if I > 7:\n",
    "            return False\n",
    "        if KnownStructureCheck(self, SpeciesArrayToInt(C2)):\n",
    "            break\n",
    "        I += 1\n",
    "    print PA\n",
    "    print C1\n",
    "    print C2\n",
    "#     if (PA != C1+C2).all():\n",
    "#         return False\n",
    "#     if np.sum(PA) != (np.sum(C1) + np.sum(C1)):\n",
    "#         return False\n",
    "    POut = SpeciesArrayToInt(PA)\n",
    "    C1Out = SpeciesArrayToInt(C1)\n",
    "    C2Out = SpeciesArrayToInt(C2)\n",
    "    if self.SpeciesNumberLookup(C1Out) > self.SpeciesNumberLookup(C2Out):\n",
    "        pass\n",
    "    else:\n",
    "        CT = C1Out\n",
    "        C1Out = C2Out\n",
    "        C2Out = CT\n",
    "#     return self.SpeciesNumberLookup(POut), self.SpeciesNumberLookup(C1Out), self.SpeciesNumberLookup(C2Out)\n",
    "    return POut, C1Out, C2Out\n",
    "#     return SpeciesToArrays(POut), SpeciesToArrays(C1Out), SpeciesToArrays(C2Out)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# D.Children(39,40)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "SpeciesToArrays(7) + SpeciesToArrays(56)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# D.Children(39,32)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# np.sum(D.SpeciesNumbers == SpeciesArrayToInt(Children(D, 39,32)[2]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# SpeciesArrayToInt(Children(D, 39,32)[2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# SpeciesArrayToInt(SpeciesToArrays(7))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "D.Species.values()[0][::2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "D.Species.values()[0][::2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "D.Species.values()[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%timeit T = {y:x for (x,y) in D.Species.items()}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "D.SpeciesIndex"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%timeit \n",
    "T = {y:x for (x,y) in D.Species.items()}\n",
    "T['1,0,0;0,0,0']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "T = frozenset([5,5,4])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import collections\n",
    "isinstance(T, collections.Hashable)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataViewer27 Python 2.7.14",
   "language": "python",
   "name": "dataviewer27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
